{
  "best_global_step": 4000,
  "best_metric": 0.0254677701741457,
  "best_model_checkpoint": "./results-juliet-lora\\checkpoint-4000",
  "epoch": 0.6608293408227325,
  "eval_steps": 1000,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03304146704113663,
      "grad_norm": 4.72982931137085,
      "learning_rate": 0.00019342474805881382,
      "loss": 0.435,
      "step": 200
    },
    {
      "epoch": 0.06608293408227325,
      "grad_norm": 0.04648420959711075,
      "learning_rate": 0.00018681645465058652,
      "loss": 0.107,
      "step": 400
    },
    {
      "epoch": 0.09912440112340988,
      "grad_norm": 0.49343162775039673,
      "learning_rate": 0.00018020816124235918,
      "loss": 0.0568,
      "step": 600
    },
    {
      "epoch": 0.1321658681645465,
      "grad_norm": 2.5422255992889404,
      "learning_rate": 0.00017359986783413184,
      "loss": 0.0467,
      "step": 800
    },
    {
      "epoch": 0.16520733520568312,
      "grad_norm": 0.0010310417274013162,
      "learning_rate": 0.0001669915744259045,
      "loss": 0.0382,
      "step": 1000
    },
    {
      "epoch": 0.16520733520568312,
      "eval_loss": 0.041475918143987656,
      "eval_runtime": 310.0435,
      "eval_samples_per_second": 52.064,
      "eval_steps_per_second": 2.171,
      "step": 1000
    },
    {
      "epoch": 0.19824880224681976,
      "grad_norm": 0.019034255295991898,
      "learning_rate": 0.0001603832810176772,
      "loss": 0.0326,
      "step": 1200
    },
    {
      "epoch": 0.23129026928795637,
      "grad_norm": 0.011045219376683235,
      "learning_rate": 0.00015377498760944986,
      "loss": 0.0375,
      "step": 1400
    },
    {
      "epoch": 0.264331736329093,
      "grad_norm": 0.019738418981432915,
      "learning_rate": 0.00014716669420122253,
      "loss": 0.0355,
      "step": 1600
    },
    {
      "epoch": 0.29737320337022966,
      "grad_norm": 0.0065198070369660854,
      "learning_rate": 0.00014055840079299522,
      "loss": 0.03,
      "step": 1800
    },
    {
      "epoch": 0.33041467041136624,
      "grad_norm": 0.020009219646453857,
      "learning_rate": 0.0001339501073847679,
      "loss": 0.0366,
      "step": 2000
    },
    {
      "epoch": 0.33041467041136624,
      "eval_loss": 0.07893144339323044,
      "eval_runtime": 426.4485,
      "eval_samples_per_second": 37.852,
      "eval_steps_per_second": 1.578,
      "step": 2000
    },
    {
      "epoch": 0.3634561374525029,
      "grad_norm": 0.421097069978714,
      "learning_rate": 0.00012734181397654057,
      "loss": 0.0389,
      "step": 2200
    },
    {
      "epoch": 0.3964976044936395,
      "grad_norm": 2.008267402648926,
      "learning_rate": 0.00012073352056831324,
      "loss": 0.0333,
      "step": 2400
    },
    {
      "epoch": 0.42953907153477616,
      "grad_norm": 0.035939622670412064,
      "learning_rate": 0.00011412522716008592,
      "loss": 0.0302,
      "step": 2600
    },
    {
      "epoch": 0.46258053857591275,
      "grad_norm": 0.0037807824555784464,
      "learning_rate": 0.00010751693375185858,
      "loss": 0.0294,
      "step": 2800
    },
    {
      "epoch": 0.4956220056170494,
      "grad_norm": 0.41700029373168945,
      "learning_rate": 0.00010090864034363126,
      "loss": 0.0287,
      "step": 3000
    },
    {
      "epoch": 0.4956220056170494,
      "eval_loss": 0.02705429680645466,
      "eval_runtime": 382.3972,
      "eval_samples_per_second": 42.213,
      "eval_steps_per_second": 1.76,
      "step": 3000
    },
    {
      "epoch": 0.528663472658186,
      "grad_norm": 0.5179293155670166,
      "learning_rate": 9.430034693540394e-05,
      "loss": 0.0232,
      "step": 3200
    },
    {
      "epoch": 0.5617049396993227,
      "grad_norm": 0.20550692081451416,
      "learning_rate": 8.769205352717661e-05,
      "loss": 0.0345,
      "step": 3400
    },
    {
      "epoch": 0.5947464067404593,
      "grad_norm": 0.2355141043663025,
      "learning_rate": 8.108376011894928e-05,
      "loss": 0.0331,
      "step": 3600
    },
    {
      "epoch": 0.627787873781596,
      "grad_norm": 0.00466053606942296,
      "learning_rate": 7.447546671072197e-05,
      "loss": 0.0289,
      "step": 3800
    },
    {
      "epoch": 0.6608293408227325,
      "grad_norm": 0.2573240101337433,
      "learning_rate": 6.786717330249463e-05,
      "loss": 0.0287,
      "step": 4000
    },
    {
      "epoch": 0.6608293408227325,
      "eval_loss": 0.0254677701741457,
      "eval_runtime": 419.1179,
      "eval_samples_per_second": 38.514,
      "eval_steps_per_second": 1.606,
      "step": 4000
    }
  ],
  "logging_steps": 200,
  "max_steps": 6053,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.5520260644864e+16,
  "train_batch_size": 24,
  "trial_name": null,
  "trial_params": null
}
